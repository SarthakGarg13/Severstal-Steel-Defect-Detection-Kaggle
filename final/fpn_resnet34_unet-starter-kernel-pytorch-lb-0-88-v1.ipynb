{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet starter for Steel defect detection challenge\n",
    "\n",
    "\n",
    "This kernel uses a UNet model with pretrained resnet18 encoder for this challenge, with simple augmentations using albumentations library, uses BCE loss, metrics like Dice and IoU. I've used [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) which comes with a lot pre-implemented segmentation architectures. This is a modified version of my previous [kernel](https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch) for [siim-acr-pneumothorax-segmentation](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/) competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As internet is not allowed for this competition, I tried installing `segmentation_models.pytorch` by source using pip but due to some reasons it didn't work. So, as a [Jugaad](https://en.wikipedia.org/wiki/Jugaad) I took all of `segmentation_models.pytorch`'s UNet code and wrote it in a single file and added it as a dataset so as to use it for this kernel, its dependency [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch) is also added as a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/qubvel/segmentation_models.pytorch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'resnet34'\n",
    "mask_size = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# !pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\n",
    "# package_path = './unetmodelscript/' # add unet script dataset\n",
    "# import sys\n",
    "# sys.path.append(package_path)\n",
    "# from model import Unet # import Unet model from the script\n",
    "import segmentation_models_pytorch as smp #import Unet, FPN, PSPNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.torch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from radam import RAdam\n",
    "\n",
    "from torchsample.callbacks import EarlyStopping\n",
    "from lovasz_loss import LovaszSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, mask_size, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * mask_size, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, mask_size, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.5), # only horizontal flip as of now\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Resize(256, mask_size),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more utility functions\n",
    "\n",
    "Dice and IoU metric implementations, metric logger for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.dice_pos_scores.append(dice_pos)\n",
    "        self.dice_neg_scores.append(dice_neg)\n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        dice_neg = np.mean(self.dice_neg_scores)\n",
    "        dice_pos = np.mean(self.dice_pos_scores)\n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        return dices, iou\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
    "    return dice, iou\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "    return ious if ious else [1]\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCESoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, w1=1, w2=1):\n",
    "        super(BCESoftDiceLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # BCELoss2d\n",
    "        probs        = torch.sigmoid(logits)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        bce_loss = self.bce_loss(probs_flat, targets_flat)\n",
    "        \n",
    "        # SoftDiceLoss\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1  = probs.view(num,-1)\n",
    "        m2  = targets.view(num,-1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "        soft_dice_loss = 1- score.sum()/num\n",
    "        \n",
    "        return self.w1 * bce_loss + self.w2 * soft_dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /tmp/.cache/torch/checkpoints/\n",
    "# !cp ../input/resnet18/resnet18.pth /tmp/.cache/torch/checkpoints/resnet18-5c106cde.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "model = smp.FPN(encoder_name, encoder_weights=\"imagenet\", classes=4, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "# model.set_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (s5): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "    (final_conv): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # a *deeper* look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 3\n",
    "        self.batch_size = {\"train\": 16, \"val\": 16}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.lr = 5e-4\n",
    "        self.num_epochs = 1000\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        # self.criterion = LovaszSoftmax()\n",
    "        # self.criterion = BCESoftDiceLoss(w1=1, w2=1)\n",
    "        # self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.optimizer = RAdam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        outputs = self.net(images)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"./\"+encoder_name+\"_model.pth\")\n",
    "            if epoch % 10 == 0:\n",
    "                torch.save(state, \"./\"+encoder_name+\"_model_epoch_\"+str(epoch)+\".pth\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/sample_submission.csv'\n",
    "train_df_path = '../input/train.csv'\n",
    "data_folder = \"../input/\"\n",
    "test_data_folder = \"../input/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | ⏰: 20:58:32\n",
      "Loss: 0.0778 | IoU: 0.1881 | dice: 0.4258 | dice_neg: 0.6255 | dice_pos: 0.2590\n",
      "Starting epoch: 0 | phase: val | ⏰: 21:05:55\n",
      "Loss: 0.0141 | IoU: 0.3197 | dice: 0.6524 | dice_neg: 0.9192 | dice_pos: 0.4181\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 1 | phase: train | ⏰: 21:07:10\n",
      "Loss: 0.0150 | IoU: 0.3453 | dice: 0.6258 | dice_neg: 0.8385 | dice_pos: 0.4488\n",
      "Starting epoch: 1 | phase: val | ⏰: 21:14:24\n",
      "Loss: 0.0136 | IoU: 0.4181 | dice: 0.6784 | dice_neg: 0.8440 | dice_pos: 0.5297\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 2 | phase: train | ⏰: 21:15:39\n",
      "Loss: 0.0131 | IoU: 0.4022 | dice: 0.6702 | dice_neg: 0.8556 | dice_pos: 0.5150\n",
      "Starting epoch: 2 | phase: val | ⏰: 21:22:53\n",
      "Loss: 0.0123 | IoU: 0.4205 | dice: 0.7224 | dice_neg: 0.9205 | dice_pos: 0.5376\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 3 | phase: train | ⏰: 21:24:08\n",
      "Loss: 0.0124 | IoU: 0.4333 | dice: 0.6930 | dice_neg: 0.8606 | dice_pos: 0.5522\n",
      "Starting epoch: 3 | phase: val | ⏰: 21:31:22\n",
      "Loss: 0.0122 | IoU: 0.3872 | dice: 0.7117 | dice_neg: 0.9488 | dice_pos: 0.4997\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 4 | phase: train | ⏰: 21:32:36\n",
      "Loss: 0.0122 | IoU: 0.4413 | dice: 0.6965 | dice_neg: 0.8602 | dice_pos: 0.5615\n",
      "Starting epoch: 4 | phase: val | ⏰: 21:39:49\n",
      "Loss: 0.0103 | IoU: 0.5028 | dice: 0.7484 | dice_neg: 0.8810 | dice_pos: 0.6310\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 5 | phase: train | ⏰: 21:41:04\n",
      "Loss: 0.0115 | IoU: 0.4666 | dice: 0.7148 | dice_neg: 0.8671 | dice_pos: 0.5886\n",
      "Starting epoch: 5 | phase: val | ⏰: 21:48:17\n",
      "Loss: 0.0122 | IoU: 0.4435 | dice: 0.7409 | dice_neg: 0.9411 | dice_pos: 0.5568\n",
      "\n",
      "Starting epoch: 6 | phase: train | ⏰: 21:49:31\n",
      "Loss: 0.0107 | IoU: 0.4844 | dice: 0.7270 | dice_neg: 0.8756 | dice_pos: 0.6069\n",
      "Starting epoch: 6 | phase: val | ⏰: 21:56:48\n",
      "Loss: 0.0108 | IoU: 0.4971 | dice: 0.7577 | dice_neg: 0.9134 | dice_pos: 0.6201\n",
      "\n",
      "Starting epoch: 7 | phase: train | ⏰: 21:58:07\n",
      "Loss: 0.0102 | IoU: 0.4946 | dice: 0.7373 | dice_neg: 0.8827 | dice_pos: 0.6184\n",
      "Starting epoch: 7 | phase: val | ⏰: 22:05:29\n",
      "Loss: 0.0123 | IoU: 0.4218 | dice: 0.7267 | dice_neg: 0.9383 | dice_pos: 0.5424\n",
      "\n",
      "Starting epoch: 8 | phase: train | ⏰: 22:06:43\n",
      "Loss: 0.0094 | IoU: 0.5185 | dice: 0.7560 | dice_neg: 0.8967 | dice_pos: 0.6427\n",
      "Starting epoch: 8 | phase: val | ⏰: 22:13:57\n",
      "Loss: 0.0099 | IoU: 0.5166 | dice: 0.7757 | dice_neg: 0.9305 | dice_pos: 0.6394\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 9 | phase: train | ⏰: 22:15:11\n",
      "Loss: 0.0093 | IoU: 0.5213 | dice: 0.7613 | dice_neg: 0.9013 | dice_pos: 0.6445\n",
      "Starting epoch: 9 | phase: val | ⏰: 22:22:23\n",
      "Loss: 0.0101 | IoU: 0.5408 | dice: 0.7779 | dice_neg: 0.9019 | dice_pos: 0.6637\n",
      "\n",
      "Starting epoch: 10 | phase: train | ⏰: 22:23:37\n",
      "Loss: 0.0094 | IoU: 0.5234 | dice: 0.7627 | dice_neg: 0.9026 | dice_pos: 0.6464\n",
      "Starting epoch: 10 | phase: val | ⏰: 22:30:51\n",
      "Loss: 0.0104 | IoU: 0.4833 | dice: 0.7553 | dice_neg: 0.9264 | dice_pos: 0.6057\n",
      "\n",
      "Starting epoch: 11 | phase: train | ⏰: 22:32:06\n",
      "Loss: 0.0102 | IoU: 0.5049 | dice: 0.7426 | dice_neg: 0.8789 | dice_pos: 0.6264\n",
      "Starting epoch: 11 | phase: val | ⏰: 22:39:17\n",
      "Loss: 0.0127 | IoU: 0.4307 | dice: 0.7322 | dice_neg: 0.9475 | dice_pos: 0.5420\n",
      "\n",
      "Starting epoch: 12 | phase: train | ⏰: 22:40:32\n",
      "Loss: 0.0101 | IoU: 0.5067 | dice: 0.7448 | dice_neg: 0.8844 | dice_pos: 0.6284\n",
      "Starting epoch: 12 | phase: val | ⏰: 22:47:44\n",
      "Loss: 0.0118 | IoU: 0.5167 | dice: 0.7305 | dice_neg: 0.8239 | dice_pos: 0.6445\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-05.\n",
      "\n",
      "Starting epoch: 13 | phase: train | ⏰: 22:48:58\n",
      "Loss: 0.0077 | IoU: 0.5764 | dice: 0.8009 | dice_neg: 0.9223 | dice_pos: 0.6994\n",
      "Starting epoch: 13 | phase: val | ⏰: 22:56:09\n",
      "Loss: 0.0095 | IoU: 0.5558 | dice: 0.7893 | dice_neg: 0.9102 | dice_pos: 0.6806\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 14 | phase: train | ⏰: 22:57:23\n",
      "Loss: 0.0070 | IoU: 0.5960 | dice: 0.8217 | dice_neg: 0.9443 | dice_pos: 0.7183\n",
      "Starting epoch: 14 | phase: val | ⏰: 23:04:36\n",
      "Loss: 0.0095 | IoU: 0.5649 | dice: 0.7992 | dice_neg: 0.9226 | dice_pos: 0.6890\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 15 | phase: train | ⏰: 23:05:50\n",
      "Loss: 0.0067 | IoU: 0.6086 | dice: 0.8314 | dice_neg: 0.9502 | dice_pos: 0.7307\n",
      "Starting epoch: 15 | phase: val | ⏰: 23:13:02\n",
      "Loss: 0.0096 | IoU: 0.5576 | dice: 0.8036 | dice_neg: 0.9380 | dice_pos: 0.6776\n",
      "\n",
      "Starting epoch: 16 | phase: train | ⏰: 23:14:15\n",
      "Loss: 0.0064 | IoU: 0.6193 | dice: 0.8349 | dice_neg: 0.9483 | dice_pos: 0.7396\n",
      "Starting epoch: 16 | phase: val | ⏰: 23:21:28\n",
      "Loss: 0.0099 | IoU: 0.5597 | dice: 0.8067 | dice_neg: 0.9496 | dice_pos: 0.6806\n",
      "\n",
      "Starting epoch: 17 | phase: train | ⏰: 23:22:42\n",
      "Loss: 0.0062 | IoU: 0.6249 | dice: 0.8396 | dice_neg: 0.9493 | dice_pos: 0.7445\n",
      "Starting epoch: 17 | phase: val | ⏰: 23:29:54\n",
      "Loss: 0.0099 | IoU: 0.5600 | dice: 0.8053 | dice_neg: 0.9417 | dice_pos: 0.6830\n",
      "\n",
      "Starting epoch: 18 | phase: train | ⏰: 23:31:09\n",
      "Loss: 0.0060 | IoU: 0.6336 | dice: 0.8451 | dice_neg: 0.9557 | dice_pos: 0.7531\n",
      "Starting epoch: 18 | phase: val | ⏰: 23:38:22\n",
      "Loss: 0.0099 | IoU: 0.5751 | dice: 0.8101 | dice_neg: 0.9358 | dice_pos: 0.6982\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0000e-06.\n",
      "\n",
      "Starting epoch: 19 | phase: train | ⏰: 23:39:36\n",
      "Loss: 0.0056 | IoU: 0.6460 | dice: 0.8496 | dice_neg: 0.9508 | dice_pos: 0.7634\n",
      "Starting epoch: 19 | phase: val | ⏰: 23:46:48\n",
      "Loss: 0.0100 | IoU: 0.5660 | dice: 0.8094 | dice_neg: 0.9440 | dice_pos: 0.6883\n",
      "\n",
      "Starting epoch: 20 | phase: train | ⏰: 23:48:02\n",
      "Loss: 0.0055 | IoU: 0.6493 | dice: 0.8543 | dice_neg: 0.9584 | dice_pos: 0.7662\n",
      "Starting epoch: 20 | phase: val | ⏰: 23:55:18\n",
      "Loss: 0.0102 | IoU: 0.5691 | dice: 0.8116 | dice_neg: 0.9408 | dice_pos: 0.6915\n",
      "\n",
      "Starting epoch: 21 | phase: train | ⏰: 23:56:35\n",
      "Loss: 0.0054 | IoU: 0.6525 | dice: 0.8565 | dice_neg: 0.9605 | dice_pos: 0.7686\n",
      "Starting epoch: 21 | phase: val | ⏰: 00:03:48\n",
      "Loss: 0.0101 | IoU: 0.5740 | dice: 0.8105 | dice_neg: 0.9393 | dice_pos: 0.6927\n",
      "\n",
      "Starting epoch: 22 | phase: train | ⏰: 00:05:02\n",
      "Loss: 0.0054 | IoU: 0.6522 | dice: 0.8559 | dice_neg: 0.9561 | dice_pos: 0.7687\n",
      "Starting epoch: 22 | phase: val | ⏰: 00:12:17\n",
      "Loss: 0.0102 | IoU: 0.5671 | dice: 0.8084 | dice_neg: 0.9351 | dice_pos: 0.6896\n",
      "Epoch    22: reducing learning rate of group 0 to 5.0000e-07.\n",
      "\n",
      "Starting epoch: 23 | phase: train | ⏰: 00:13:31\n",
      "Loss: 0.0054 | IoU: 0.6538 | dice: 0.8600 | dice_neg: 0.9649 | dice_pos: 0.7697\n",
      "Starting epoch: 23 | phase: val | ⏰: 00:20:43\n",
      "Loss: 0.0104 | IoU: 0.5708 | dice: 0.8094 | dice_neg: 0.9324 | dice_pos: 0.6939\n",
      "\n",
      "Starting epoch: 24 | phase: train | ⏰: 00:21:58\n",
      "Loss: 0.0054 | IoU: 0.6563 | dice: 0.8586 | dice_neg: 0.9619 | dice_pos: 0.7722\n",
      "Starting epoch: 24 | phase: val | ⏰: 00:29:13\n",
      "Loss: 0.0102 | IoU: 0.5710 | dice: 0.8121 | dice_neg: 0.9479 | dice_pos: 0.6935\n",
      "\n",
      "Starting epoch: 25 | phase: train | ⏰: 00:30:27\n",
      "Loss: 0.0054 | IoU: 0.6561 | dice: 0.8594 | dice_neg: 0.9604 | dice_pos: 0.7719\n",
      "Starting epoch: 25 | phase: val | ⏰: 00:37:44\n",
      "Loss: 0.0103 | IoU: 0.5740 | dice: 0.8094 | dice_neg: 0.9362 | dice_pos: 0.6973\n",
      "\n",
      "Starting epoch: 26 | phase: train | ⏰: 00:38:59\n",
      "Loss: 0.0053 | IoU: 0.6573 | dice: 0.8594 | dice_neg: 0.9621 | dice_pos: 0.7733\n",
      "Starting epoch: 26 | phase: val | ⏰: 00:46:15\n",
      "Loss: 0.0102 | IoU: 0.5729 | dice: 0.8081 | dice_neg: 0.9297 | dice_pos: 0.6957\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0000e-08.\n",
      "\n",
      "Starting epoch: 27 | phase: train | ⏰: 00:47:30\n",
      "Loss: 0.0053 | IoU: 0.6569 | dice: 0.8594 | dice_neg: 0.9610 | dice_pos: 0.7728\n",
      "Starting epoch: 27 | phase: val | ⏰: 00:54:43\n",
      "Loss: 0.0103 | IoU: 0.5757 | dice: 0.8108 | dice_neg: 0.9378 | dice_pos: 0.6982\n",
      "\n",
      "Starting epoch: 28 | phase: train | ⏰: 00:55:57\n",
      "Loss: 0.0054 | IoU: 0.6577 | dice: 0.8584 | dice_neg: 0.9614 | dice_pos: 0.7733\n",
      "Starting epoch: 28 | phase: val | ⏰: 01:03:19\n",
      "Loss: 0.0103 | IoU: 0.5698 | dice: 0.8102 | dice_neg: 0.9393 | dice_pos: 0.6928\n",
      "\n",
      "Starting epoch: 29 | phase: train | ⏰: 01:04:36\n",
      "Loss: 0.0053 | IoU: 0.6592 | dice: 0.8606 | dice_neg: 0.9613 | dice_pos: 0.7751\n",
      "Starting epoch: 29 | phase: val | ⏰: 01:11:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0101 | IoU: 0.5746 | dice: 0.8119 | dice_neg: 0.9361 | dice_pos: 0.6930\n",
      "\n",
      "Starting epoch: 30 | phase: train | ⏰: 01:13:14\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8615 | dice_neg: 0.9633 | dice_pos: 0.7741\n",
      "Starting epoch: 30 | phase: val | ⏰: 01:20:36\n",
      "Loss: 0.0103 | IoU: 0.5735 | dice: 0.8096 | dice_neg: 0.9391 | dice_pos: 0.6967\n",
      "Epoch    30: reducing learning rate of group 0 to 5.0000e-09.\n",
      "\n",
      "Starting epoch: 31 | phase: train | ⏰: 01:21:53\n",
      "Loss: 0.0053 | IoU: 0.6565 | dice: 0.8598 | dice_neg: 0.9623 | dice_pos: 0.7722\n",
      "Starting epoch: 31 | phase: val | ⏰: 01:29:12\n",
      "Loss: 0.0101 | IoU: 0.5761 | dice: 0.8101 | dice_neg: 0.9333 | dice_pos: 0.6988\n",
      "\n",
      "Starting epoch: 32 | phase: train | ⏰: 01:30:29\n",
      "Loss: 0.0054 | IoU: 0.6563 | dice: 0.8576 | dice_neg: 0.9566 | dice_pos: 0.7723\n",
      "Starting epoch: 32 | phase: val | ⏰: 01:37:50\n",
      "Loss: 0.0103 | IoU: 0.5702 | dice: 0.8104 | dice_neg: 0.9349 | dice_pos: 0.6925\n",
      "\n",
      "Starting epoch: 33 | phase: train | ⏰: 01:39:07\n",
      "Loss: 0.0054 | IoU: 0.6546 | dice: 0.8575 | dice_neg: 0.9624 | dice_pos: 0.7704\n",
      "Starting epoch: 33 | phase: val | ⏰: 01:46:29\n",
      "Loss: 0.0106 | IoU: 0.5733 | dice: 0.8096 | dice_neg: 0.9376 | dice_pos: 0.6967\n",
      "\n",
      "Starting epoch: 34 | phase: train | ⏰: 01:47:46\n",
      "Loss: 0.0054 | IoU: 0.6573 | dice: 0.8594 | dice_neg: 0.9596 | dice_pos: 0.7731\n",
      "Starting epoch: 34 | phase: val | ⏰: 01:55:09\n",
      "Loss: 0.0104 | IoU: 0.5730 | dice: 0.8121 | dice_neg: 0.9377 | dice_pos: 0.6958\n",
      "\n",
      "Starting epoch: 35 | phase: train | ⏰: 01:56:26\n",
      "Loss: 0.0053 | IoU: 0.6570 | dice: 0.8588 | dice_neg: 0.9581 | dice_pos: 0.7734\n",
      "Starting epoch: 35 | phase: val | ⏰: 02:03:54\n",
      "Loss: 0.0101 | IoU: 0.5747 | dice: 0.8079 | dice_neg: 0.9269 | dice_pos: 0.6987\n",
      "\n",
      "Starting epoch: 36 | phase: train | ⏰: 02:05:14\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8591 | dice_neg: 0.9599 | dice_pos: 0.7739\n",
      "Starting epoch: 36 | phase: val | ⏰: 02:12:42\n",
      "Loss: 0.0105 | IoU: 0.5713 | dice: 0.8114 | dice_neg: 0.9410 | dice_pos: 0.6947\n",
      "\n",
      "Starting epoch: 37 | phase: train | ⏰: 02:13:59\n",
      "Loss: 0.0053 | IoU: 0.6565 | dice: 0.8571 | dice_neg: 0.9563 | dice_pos: 0.7724\n",
      "Starting epoch: 37 | phase: val | ⏰: 02:21:25\n",
      "Loss: 0.0103 | IoU: 0.5690 | dice: 0.8108 | dice_neg: 0.9429 | dice_pos: 0.6915\n",
      "\n",
      "Starting epoch: 38 | phase: train | ⏰: 02:22:45\n",
      "Loss: 0.0053 | IoU: 0.6562 | dice: 0.8590 | dice_neg: 0.9605 | dice_pos: 0.7728\n",
      "Starting epoch: 38 | phase: val | ⏰: 02:30:17\n",
      "Loss: 0.0103 | IoU: 0.5736 | dice: 0.8123 | dice_neg: 0.9431 | dice_pos: 0.6958\n",
      "\n",
      "Starting epoch: 39 | phase: train | ⏰: 02:31:40\n",
      "Loss: 0.0053 | IoU: 0.6545 | dice: 0.8573 | dice_neg: 0.9583 | dice_pos: 0.7705\n",
      "Starting epoch: 39 | phase: val | ⏰: 02:39:07\n",
      "Loss: 0.0102 | IoU: 0.5691 | dice: 0.8102 | dice_neg: 0.9405 | dice_pos: 0.6917\n",
      "\n",
      "Starting epoch: 40 | phase: train | ⏰: 02:40:27\n",
      "Loss: 0.0054 | IoU: 0.6586 | dice: 0.8596 | dice_neg: 0.9606 | dice_pos: 0.7746\n",
      "Starting epoch: 40 | phase: val | ⏰: 02:47:58\n",
      "Loss: 0.0102 | IoU: 0.5731 | dice: 0.8112 | dice_neg: 0.9389 | dice_pos: 0.6919\n",
      "\n",
      "Starting epoch: 41 | phase: train | ⏰: 02:49:18\n",
      "Loss: 0.0053 | IoU: 0.6573 | dice: 0.8594 | dice_neg: 0.9611 | dice_pos: 0.7731\n",
      "Starting epoch: 41 | phase: val | ⏰: 02:56:40\n",
      "Loss: 0.0102 | IoU: 0.5724 | dice: 0.8128 | dice_neg: 0.9487 | dice_pos: 0.6946\n",
      "\n",
      "Starting epoch: 42 | phase: train | ⏰: 02:57:57\n",
      "Loss: 0.0053 | IoU: 0.6569 | dice: 0.8593 | dice_neg: 0.9604 | dice_pos: 0.7731\n",
      "Starting epoch: 42 | phase: val | ⏰: 03:05:19\n",
      "Loss: 0.0102 | IoU: 0.5761 | dice: 0.8110 | dice_neg: 0.9378 | dice_pos: 0.6992\n",
      "\n",
      "Starting epoch: 43 | phase: train | ⏰: 03:06:37\n",
      "Loss: 0.0054 | IoU: 0.6562 | dice: 0.8584 | dice_neg: 0.9610 | dice_pos: 0.7718\n",
      "Starting epoch: 43 | phase: val | ⏰: 03:14:00\n",
      "Loss: 0.0102 | IoU: 0.5727 | dice: 0.8121 | dice_neg: 0.9427 | dice_pos: 0.6960\n",
      "\n",
      "Starting epoch: 44 | phase: train | ⏰: 03:15:17\n",
      "Loss: 0.0053 | IoU: 0.6550 | dice: 0.8583 | dice_neg: 0.9601 | dice_pos: 0.7706\n",
      "Starting epoch: 44 | phase: val | ⏰: 03:22:39\n",
      "Loss: 0.0103 | IoU: 0.5727 | dice: 0.8129 | dice_neg: 0.9441 | dice_pos: 0.6908\n",
      "\n",
      "Starting epoch: 45 | phase: train | ⏰: 03:23:56\n",
      "Loss: 0.0053 | IoU: 0.6602 | dice: 0.8608 | dice_neg: 0.9603 | dice_pos: 0.7761\n",
      "Starting epoch: 45 | phase: val | ⏰: 03:31:21\n",
      "Loss: 0.0102 | IoU: 0.5704 | dice: 0.8107 | dice_neg: 0.9445 | dice_pos: 0.6929\n",
      "\n",
      "Starting epoch: 46 | phase: train | ⏰: 03:32:41\n",
      "Loss: 0.0053 | IoU: 0.6573 | dice: 0.8586 | dice_neg: 0.9580 | dice_pos: 0.7734\n",
      "Starting epoch: 46 | phase: val | ⏰: 03:40:20\n",
      "Loss: 0.0103 | IoU: 0.5723 | dice: 0.8126 | dice_neg: 0.9461 | dice_pos: 0.6895\n",
      "\n",
      "Starting epoch: 47 | phase: train | ⏰: 03:41:43\n",
      "Loss: 0.0053 | IoU: 0.6566 | dice: 0.8574 | dice_neg: 0.9586 | dice_pos: 0.7724\n",
      "Starting epoch: 47 | phase: val | ⏰: 03:49:03\n",
      "Loss: 0.0104 | IoU: 0.5700 | dice: 0.8098 | dice_neg: 0.9384 | dice_pos: 0.6926\n",
      "\n",
      "Starting epoch: 48 | phase: train | ⏰: 03:50:20\n",
      "Loss: 0.0053 | IoU: 0.6566 | dice: 0.8604 | dice_neg: 0.9633 | dice_pos: 0.7729\n",
      "Starting epoch: 48 | phase: val | ⏰: 03:57:43\n",
      "Loss: 0.0103 | IoU: 0.5731 | dice: 0.8108 | dice_neg: 0.9425 | dice_pos: 0.6955\n",
      "\n",
      "Starting epoch: 49 | phase: train | ⏰: 03:59:00\n",
      "Loss: 0.0054 | IoU: 0.6557 | dice: 0.8590 | dice_neg: 0.9615 | dice_pos: 0.7722\n",
      "Starting epoch: 49 | phase: val | ⏰: 04:06:23\n",
      "Loss: 0.0102 | IoU: 0.5728 | dice: 0.8115 | dice_neg: 0.9430 | dice_pos: 0.6907\n",
      "\n",
      "Starting epoch: 50 | phase: train | ⏰: 04:07:40\n",
      "Loss: 0.0053 | IoU: 0.6556 | dice: 0.8595 | dice_neg: 0.9617 | dice_pos: 0.7718\n",
      "Starting epoch: 50 | phase: val | ⏰: 04:15:10\n",
      "Loss: 0.0104 | IoU: 0.5668 | dice: 0.8102 | dice_neg: 0.9461 | dice_pos: 0.6893\n",
      "\n",
      "Starting epoch: 51 | phase: train | ⏰: 04:16:30\n",
      "Loss: 0.0053 | IoU: 0.6586 | dice: 0.8616 | dice_neg: 0.9625 | dice_pos: 0.7734\n",
      "Starting epoch: 51 | phase: val | ⏰: 04:23:56\n",
      "Loss: 0.0102 | IoU: 0.5756 | dice: 0.8112 | dice_neg: 0.9358 | dice_pos: 0.6986\n",
      "\n",
      "Starting epoch: 52 | phase: train | ⏰: 04:25:13\n",
      "Loss: 0.0053 | IoU: 0.6597 | dice: 0.8591 | dice_neg: 0.9592 | dice_pos: 0.7753\n",
      "Starting epoch: 52 | phase: val | ⏰: 04:32:36\n",
      "Loss: 0.0104 | IoU: 0.5682 | dice: 0.8110 | dice_neg: 0.9386 | dice_pos: 0.6899\n",
      "\n",
      "Starting epoch: 53 | phase: train | ⏰: 04:33:54\n",
      "Loss: 0.0053 | IoU: 0.6551 | dice: 0.8588 | dice_neg: 0.9605 | dice_pos: 0.7701\n",
      "Starting epoch: 53 | phase: val | ⏰: 04:41:17\n",
      "Loss: 0.0102 | IoU: 0.5733 | dice: 0.8106 | dice_neg: 0.9355 | dice_pos: 0.6921\n",
      "\n",
      "Starting epoch: 54 | phase: train | ⏰: 04:42:35\n",
      "Loss: 0.0053 | IoU: 0.6569 | dice: 0.8591 | dice_neg: 0.9605 | dice_pos: 0.7733\n",
      "Starting epoch: 54 | phase: val | ⏰: 04:50:09\n",
      "Loss: 0.0103 | IoU: 0.5757 | dice: 0.8123 | dice_neg: 0.9464 | dice_pos: 0.6980\n",
      "\n",
      "Starting epoch: 55 | phase: train | ⏰: 04:51:27\n",
      "Loss: 0.0053 | IoU: 0.6586 | dice: 0.8595 | dice_neg: 0.9608 | dice_pos: 0.7742\n",
      "Starting epoch: 55 | phase: val | ⏰: 04:58:48\n",
      "Loss: 0.0104 | IoU: 0.5702 | dice: 0.8120 | dice_neg: 0.9442 | dice_pos: 0.6922\n",
      "\n",
      "Starting epoch: 56 | phase: train | ⏰: 05:00:05\n",
      "Loss: 0.0054 | IoU: 0.6568 | dice: 0.8594 | dice_neg: 0.9610 | dice_pos: 0.7732\n",
      "Starting epoch: 56 | phase: val | ⏰: 05:07:26\n",
      "Loss: 0.0102 | IoU: 0.5696 | dice: 0.8126 | dice_neg: 0.9458 | dice_pos: 0.6881\n",
      "\n",
      "Starting epoch: 57 | phase: train | ⏰: 05:08:44\n",
      "Loss: 0.0053 | IoU: 0.6563 | dice: 0.8586 | dice_neg: 0.9608 | dice_pos: 0.7723\n",
      "Starting epoch: 57 | phase: val | ⏰: 05:16:07\n",
      "Loss: 0.0103 | IoU: 0.5724 | dice: 0.8096 | dice_neg: 0.9414 | dice_pos: 0.6950\n",
      "\n",
      "Starting epoch: 58 | phase: train | ⏰: 05:17:24\n",
      "Loss: 0.0053 | IoU: 0.6565 | dice: 0.8587 | dice_neg: 0.9589 | dice_pos: 0.7723\n",
      "Starting epoch: 58 | phase: val | ⏰: 05:24:48\n",
      "Loss: 0.0103 | IoU: 0.5712 | dice: 0.8110 | dice_neg: 0.9401 | dice_pos: 0.6931\n",
      "\n",
      "Starting epoch: 59 | phase: train | ⏰: 05:26:06\n",
      "Loss: 0.0054 | IoU: 0.6551 | dice: 0.8576 | dice_neg: 0.9591 | dice_pos: 0.7710\n",
      "Starting epoch: 59 | phase: val | ⏰: 05:33:31\n",
      "Loss: 0.0103 | IoU: 0.5667 | dice: 0.8101 | dice_neg: 0.9374 | dice_pos: 0.6897\n",
      "\n",
      "Starting epoch: 60 | phase: train | ⏰: 05:34:49\n",
      "Loss: 0.0053 | IoU: 0.6593 | dice: 0.8598 | dice_neg: 0.9588 | dice_pos: 0.7753\n",
      "Starting epoch: 60 | phase: val | ⏰: 05:42:17\n",
      "Loss: 0.0103 | IoU: 0.5736 | dice: 0.8124 | dice_neg: 0.9424 | dice_pos: 0.6921\n",
      "\n",
      "Starting epoch: 61 | phase: train | ⏰: 05:43:38\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8585 | dice_neg: 0.9592 | dice_pos: 0.7743\n",
      "Starting epoch: 61 | phase: val | ⏰: 05:51:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0102 | IoU: 0.5761 | dice: 0.8124 | dice_neg: 0.9419 | dice_pos: 0.6992\n",
      "\n",
      "Starting epoch: 62 | phase: train | ⏰: 05:52:29\n",
      "Loss: 0.0054 | IoU: 0.6566 | dice: 0.8586 | dice_neg: 0.9612 | dice_pos: 0.7725\n",
      "Starting epoch: 62 | phase: val | ⏰: 05:59:56\n",
      "Loss: 0.0103 | IoU: 0.5679 | dice: 0.8131 | dice_neg: 0.9493 | dice_pos: 0.6850\n",
      "\n",
      "Starting epoch: 63 | phase: train | ⏰: 06:01:16\n",
      "Loss: 0.0053 | IoU: 0.6588 | dice: 0.8610 | dice_neg: 0.9617 | dice_pos: 0.7738\n",
      "Starting epoch: 63 | phase: val | ⏰: 06:08:46\n",
      "Loss: 0.0102 | IoU: 0.5738 | dice: 0.8112 | dice_neg: 0.9376 | dice_pos: 0.6967\n",
      "\n",
      "Starting epoch: 64 | phase: train | ⏰: 06:10:05\n",
      "Loss: 0.0053 | IoU: 0.6578 | dice: 0.8580 | dice_neg: 0.9573 | dice_pos: 0.7736\n",
      "Starting epoch: 64 | phase: val | ⏰: 06:17:26\n",
      "Loss: 0.0102 | IoU: 0.5757 | dice: 0.8118 | dice_neg: 0.9393 | dice_pos: 0.6984\n",
      "\n",
      "Starting epoch: 65 | phase: train | ⏰: 06:18:44\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8596 | dice_neg: 0.9585 | dice_pos: 0.7746\n",
      "Starting epoch: 65 | phase: val | ⏰: 06:26:35\n",
      "Loss: 0.0103 | IoU: 0.5716 | dice: 0.8106 | dice_neg: 0.9413 | dice_pos: 0.6895\n",
      "\n",
      "Starting epoch: 66 | phase: train | ⏰: 06:28:00\n",
      "Loss: 0.0054 | IoU: 0.6559 | dice: 0.8591 | dice_neg: 0.9610 | dice_pos: 0.7723\n",
      "Starting epoch: 66 | phase: val | ⏰: 06:35:26\n",
      "Loss: 0.0104 | IoU: 0.5683 | dice: 0.8117 | dice_neg: 0.9448 | dice_pos: 0.6907\n",
      "\n",
      "Starting epoch: 67 | phase: train | ⏰: 06:36:43\n",
      "Loss: 0.0053 | IoU: 0.6576 | dice: 0.8584 | dice_neg: 0.9600 | dice_pos: 0.7736\n",
      "Starting epoch: 67 | phase: val | ⏰: 06:44:04\n",
      "Loss: 0.0102 | IoU: 0.5706 | dice: 0.8111 | dice_neg: 0.9389 | dice_pos: 0.6931\n",
      "\n",
      "Starting epoch: 68 | phase: train | ⏰: 06:45:21\n",
      "Loss: 0.0054 | IoU: 0.6556 | dice: 0.8570 | dice_neg: 0.9571 | dice_pos: 0.7717\n",
      "Starting epoch: 68 | phase: val | ⏰: 06:52:48\n",
      "Loss: 0.0102 | IoU: 0.5754 | dice: 0.8094 | dice_neg: 0.9295 | dice_pos: 0.6986\n",
      "\n",
      "Starting epoch: 69 | phase: train | ⏰: 06:54:08\n",
      "Loss: 0.0053 | IoU: 0.6567 | dice: 0.8588 | dice_neg: 0.9585 | dice_pos: 0.7730\n",
      "Starting epoch: 69 | phase: val | ⏰: 07:01:51\n",
      "Loss: 0.0102 | IoU: 0.5737 | dice: 0.8098 | dice_neg: 0.9346 | dice_pos: 0.6920\n",
      "\n",
      "Starting epoch: 70 | phase: train | ⏰: 07:03:13\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8576 | dice_neg: 0.9574 | dice_pos: 0.7731\n",
      "Starting epoch: 70 | phase: val | ⏰: 07:10:41\n",
      "Loss: 0.0104 | IoU: 0.5705 | dice: 0.8102 | dice_neg: 0.9389 | dice_pos: 0.6935\n",
      "\n",
      "Starting epoch: 71 | phase: train | ⏰: 07:11:58\n",
      "Loss: 0.0053 | IoU: 0.6586 | dice: 0.8601 | dice_neg: 0.9610 | dice_pos: 0.7739\n",
      "Starting epoch: 71 | phase: val | ⏰: 07:19:17\n",
      "Loss: 0.0101 | IoU: 0.5739 | dice: 0.8125 | dice_neg: 0.9384 | dice_pos: 0.6968\n",
      "\n",
      "Starting epoch: 72 | phase: train | ⏰: 07:20:34\n",
      "Loss: 0.0054 | IoU: 0.6560 | dice: 0.8583 | dice_neg: 0.9612 | dice_pos: 0.7716\n",
      "Starting epoch: 72 | phase: val | ⏰: 07:27:56\n",
      "Loss: 0.0103 | IoU: 0.5713 | dice: 0.8116 | dice_neg: 0.9411 | dice_pos: 0.6935\n",
      "\n",
      "Starting epoch: 73 | phase: train | ⏰: 07:29:13\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8588 | dice_neg: 0.9595 | dice_pos: 0.7743\n",
      "Starting epoch: 73 | phase: val | ⏰: 07:36:33\n",
      "Loss: 0.0103 | IoU: 0.5744 | dice: 0.8111 | dice_neg: 0.9444 | dice_pos: 0.6969\n",
      "\n",
      "Starting epoch: 74 | phase: train | ⏰: 07:37:50\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8603 | dice_neg: 0.9620 | dice_pos: 0.7741\n",
      "Starting epoch: 74 | phase: val | ⏰: 07:45:13\n",
      "Loss: 0.0103 | IoU: 0.5724 | dice: 0.8112 | dice_neg: 0.9431 | dice_pos: 0.6948\n",
      "\n",
      "Starting epoch: 75 | phase: train | ⏰: 07:46:30\n",
      "Loss: 0.0053 | IoU: 0.6588 | dice: 0.8612 | dice_neg: 0.9624 | dice_pos: 0.7749\n",
      "Starting epoch: 75 | phase: val | ⏰: 07:53:52\n",
      "Loss: 0.0102 | IoU: 0.5719 | dice: 0.8117 | dice_neg: 0.9377 | dice_pos: 0.6949\n",
      "\n",
      "Starting epoch: 76 | phase: train | ⏰: 07:55:08\n",
      "Loss: 0.0054 | IoU: 0.6548 | dice: 0.8584 | dice_neg: 0.9618 | dice_pos: 0.7707\n",
      "Starting epoch: 76 | phase: val | ⏰: 08:02:30\n",
      "Loss: 0.0102 | IoU: 0.5743 | dice: 0.8101 | dice_neg: 0.9405 | dice_pos: 0.6931\n",
      "\n",
      "Starting epoch: 77 | phase: train | ⏰: 08:03:46\n",
      "Loss: 0.0054 | IoU: 0.6568 | dice: 0.8587 | dice_neg: 0.9600 | dice_pos: 0.7730\n",
      "Starting epoch: 77 | phase: val | ⏰: 08:11:16\n",
      "Loss: 0.0103 | IoU: 0.5726 | dice: 0.8099 | dice_neg: 0.9344 | dice_pos: 0.6949\n",
      "\n",
      "Starting epoch: 78 | phase: train | ⏰: 08:12:32\n",
      "Loss: 0.0054 | IoU: 0.6559 | dice: 0.8580 | dice_neg: 0.9600 | dice_pos: 0.7718\n",
      "Starting epoch: 78 | phase: val | ⏰: 08:19:52\n",
      "Loss: 0.0102 | IoU: 0.5694 | dice: 0.8110 | dice_neg: 0.9433 | dice_pos: 0.6919\n",
      "\n",
      "Starting epoch: 79 | phase: train | ⏰: 08:21:09\n",
      "Loss: 0.0053 | IoU: 0.6544 | dice: 0.8586 | dice_neg: 0.9631 | dice_pos: 0.7705\n",
      "Starting epoch: 79 | phase: val | ⏰: 08:28:31\n",
      "Loss: 0.0102 | IoU: 0.5749 | dice: 0.8114 | dice_neg: 0.9395 | dice_pos: 0.6979\n",
      "\n",
      "Starting epoch: 80 | phase: train | ⏰: 08:29:48\n",
      "Loss: 0.0053 | IoU: 0.6587 | dice: 0.8594 | dice_neg: 0.9604 | dice_pos: 0.7748\n",
      "Starting epoch: 80 | phase: val | ⏰: 08:37:10\n",
      "Loss: 0.0103 | IoU: 0.5743 | dice: 0.8114 | dice_neg: 0.9415 | dice_pos: 0.6970\n",
      "\n",
      "Starting epoch: 81 | phase: train | ⏰: 08:38:27\n",
      "Loss: 0.0053 | IoU: 0.6578 | dice: 0.8573 | dice_neg: 0.9595 | dice_pos: 0.7732\n",
      "Starting epoch: 81 | phase: val | ⏰: 08:46:15\n",
      "Loss: 0.0103 | IoU: 0.5703 | dice: 0.8135 | dice_neg: 0.9495 | dice_pos: 0.6923\n",
      "\n",
      "Starting epoch: 82 | phase: train | ⏰: 08:47:40\n",
      "Loss: 0.0053 | IoU: 0.6576 | dice: 0.8609 | dice_neg: 0.9632 | dice_pos: 0.7739\n",
      "Starting epoch: 82 | phase: val | ⏰: 08:55:07\n",
      "Loss: 0.0103 | IoU: 0.5742 | dice: 0.8107 | dice_neg: 0.9375 | dice_pos: 0.6965\n",
      "\n",
      "Starting epoch: 83 | phase: train | ⏰: 08:56:24\n",
      "Loss: 0.0053 | IoU: 0.6594 | dice: 0.8613 | dice_neg: 0.9631 | dice_pos: 0.7750\n",
      "Starting epoch: 83 | phase: val | ⏰: 09:03:46\n",
      "Loss: 0.0102 | IoU: 0.5762 | dice: 0.8109 | dice_neg: 0.9349 | dice_pos: 0.6954\n",
      "\n",
      "Starting epoch: 84 | phase: train | ⏰: 09:05:04\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8594 | dice_neg: 0.9590 | dice_pos: 0.7738\n",
      "Starting epoch: 84 | phase: val | ⏰: 09:12:35\n",
      "Loss: 0.0104 | IoU: 0.5750 | dice: 0.8100 | dice_neg: 0.9366 | dice_pos: 0.6975\n",
      "\n",
      "Starting epoch: 85 | phase: train | ⏰: 09:14:05\n",
      "Loss: 0.0053 | IoU: 0.6591 | dice: 0.8603 | dice_neg: 0.9617 | dice_pos: 0.7748\n",
      "Starting epoch: 85 | phase: val | ⏰: 09:21:42\n",
      "Loss: 0.0105 | IoU: 0.5701 | dice: 0.8118 | dice_neg: 0.9441 | dice_pos: 0.6932\n",
      "\n",
      "Starting epoch: 86 | phase: train | ⏰: 09:23:00\n",
      "Loss: 0.0053 | IoU: 0.6566 | dice: 0.8604 | dice_neg: 0.9626 | dice_pos: 0.7723\n",
      "Starting epoch: 86 | phase: val | ⏰: 09:30:24\n",
      "Loss: 0.0101 | IoU: 0.5747 | dice: 0.8116 | dice_neg: 0.9395 | dice_pos: 0.6937\n",
      "\n",
      "Starting epoch: 87 | phase: train | ⏰: 09:31:44\n",
      "Loss: 0.0054 | IoU: 0.6567 | dice: 0.8585 | dice_neg: 0.9602 | dice_pos: 0.7727\n",
      "Starting epoch: 87 | phase: val | ⏰: 09:39:17\n",
      "Loss: 0.0103 | IoU: 0.5713 | dice: 0.8099 | dice_neg: 0.9362 | dice_pos: 0.6890\n",
      "\n",
      "Starting epoch: 88 | phase: train | ⏰: 09:40:41\n",
      "Loss: 0.0053 | IoU: 0.6549 | dice: 0.8577 | dice_neg: 0.9594 | dice_pos: 0.7708\n",
      "Starting epoch: 88 | phase: val | ⏰: 09:48:34\n",
      "Loss: 0.0104 | IoU: 0.5739 | dice: 0.8116 | dice_neg: 0.9363 | dice_pos: 0.6973\n",
      "\n",
      "Starting epoch: 89 | phase: train | ⏰: 09:49:55\n",
      "Loss: 0.0053 | IoU: 0.6574 | dice: 0.8592 | dice_neg: 0.9589 | dice_pos: 0.7734\n",
      "Starting epoch: 89 | phase: val | ⏰: 09:57:18\n",
      "Loss: 0.0103 | IoU: 0.5714 | dice: 0.8086 | dice_neg: 0.9388 | dice_pos: 0.6895\n",
      "\n",
      "Starting epoch: 90 | phase: train | ⏰: 09:58:36\n",
      "Loss: 0.0053 | IoU: 0.6592 | dice: 0.8579 | dice_neg: 0.9582 | dice_pos: 0.7743\n",
      "Starting epoch: 90 | phase: val | ⏰: 10:06:07\n",
      "Loss: 0.0102 | IoU: 0.5668 | dice: 0.8139 | dice_neg: 0.9509 | dice_pos: 0.6898\n",
      "\n",
      "Starting epoch: 91 | phase: train | ⏰: 10:07:28\n",
      "Loss: 0.0054 | IoU: 0.6550 | dice: 0.8593 | dice_neg: 0.9612 | dice_pos: 0.7709\n",
      "Starting epoch: 91 | phase: val | ⏰: 10:14:50\n",
      "Loss: 0.0101 | IoU: 0.5765 | dice: 0.8126 | dice_neg: 0.9445 | dice_pos: 0.7000\n",
      "\n",
      "Starting epoch: 92 | phase: train | ⏰: 10:16:07\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8592 | dice_neg: 0.9601 | dice_pos: 0.7733\n",
      "Starting epoch: 92 | phase: val | ⏰: 10:23:44\n",
      "Loss: 0.0101 | IoU: 0.5704 | dice: 0.8107 | dice_neg: 0.9367 | dice_pos: 0.6925\n",
      "\n",
      "Starting epoch: 93 | phase: train | ⏰: 10:25:04\n",
      "Loss: 0.0053 | IoU: 0.6575 | dice: 0.8614 | dice_neg: 0.9628 | dice_pos: 0.7736\n",
      "Starting epoch: 93 | phase: val | ⏰: 10:32:29\n",
      "Loss: 0.0103 | IoU: 0.5718 | dice: 0.8138 | dice_neg: 0.9418 | dice_pos: 0.6943\n",
      "\n",
      "Starting epoch: 94 | phase: train | ⏰: 10:33:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0054 | IoU: 0.6536 | dice: 0.8577 | dice_neg: 0.9600 | dice_pos: 0.7700\n",
      "Starting epoch: 94 | phase: val | ⏰: 10:41:07\n",
      "Loss: 0.0103 | IoU: 0.5737 | dice: 0.8077 | dice_neg: 0.9290 | dice_pos: 0.6970\n",
      "\n",
      "Starting epoch: 95 | phase: train | ⏰: 10:42:23\n",
      "Loss: 0.0053 | IoU: 0.6591 | dice: 0.8614 | dice_neg: 0.9645 | dice_pos: 0.7751\n",
      "Starting epoch: 95 | phase: val | ⏰: 10:49:44\n",
      "Loss: 0.0102 | IoU: 0.5679 | dice: 0.8108 | dice_neg: 0.9417 | dice_pos: 0.6913\n",
      "\n",
      "Starting epoch: 96 | phase: train | ⏰: 10:51:00\n",
      "Loss: 0.0054 | IoU: 0.6571 | dice: 0.8589 | dice_neg: 0.9585 | dice_pos: 0.7734\n",
      "Starting epoch: 96 | phase: val | ⏰: 10:58:21\n",
      "Loss: 0.0102 | IoU: 0.5695 | dice: 0.8100 | dice_neg: 0.9401 | dice_pos: 0.6918\n",
      "\n",
      "Starting epoch: 97 | phase: train | ⏰: 10:59:38\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8588 | dice_neg: 0.9576 | dice_pos: 0.7742\n",
      "Starting epoch: 97 | phase: val | ⏰: 11:06:58\n",
      "Loss: 0.0102 | IoU: 0.5749 | dice: 0.8111 | dice_neg: 0.9380 | dice_pos: 0.6972\n",
      "\n",
      "Starting epoch: 98 | phase: train | ⏰: 11:08:15\n",
      "Loss: 0.0053 | IoU: 0.6570 | dice: 0.8582 | dice_neg: 0.9591 | dice_pos: 0.7729\n",
      "Starting epoch: 98 | phase: val | ⏰: 11:15:36\n",
      "Loss: 0.0103 | IoU: 0.5727 | dice: 0.8123 | dice_neg: 0.9437 | dice_pos: 0.6949\n",
      "\n",
      "Starting epoch: 99 | phase: train | ⏰: 11:16:53\n",
      "Loss: 0.0053 | IoU: 0.6564 | dice: 0.8589 | dice_neg: 0.9607 | dice_pos: 0.7722\n",
      "Starting epoch: 99 | phase: val | ⏰: 11:24:22\n",
      "Loss: 0.0103 | IoU: 0.5772 | dice: 0.8057 | dice_neg: 0.9284 | dice_pos: 0.6956\n",
      "\n",
      "Starting epoch: 100 | phase: train | ⏰: 11:25:43\n",
      "Loss: 0.0053 | IoU: 0.6548 | dice: 0.8589 | dice_neg: 0.9601 | dice_pos: 0.7710\n",
      "Starting epoch: 100 | phase: val | ⏰: 11:33:23\n",
      "Loss: 0.0104 | IoU: 0.5749 | dice: 0.8093 | dice_neg: 0.9368 | dice_pos: 0.6978\n",
      "\n",
      "Starting epoch: 101 | phase: train | ⏰: 11:34:40\n",
      "Loss: 0.0053 | IoU: 0.6563 | dice: 0.8600 | dice_neg: 0.9638 | dice_pos: 0.7726\n",
      "Starting epoch: 101 | phase: val | ⏰: 11:42:02\n",
      "Loss: 0.0102 | IoU: 0.5689 | dice: 0.8101 | dice_neg: 0.9423 | dice_pos: 0.6920\n",
      "\n",
      "Starting epoch: 102 | phase: train | ⏰: 11:43:19\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8593 | dice_neg: 0.9602 | dice_pos: 0.7740\n",
      "Starting epoch: 102 | phase: val | ⏰: 11:50:41\n",
      "Loss: 0.0105 | IoU: 0.5706 | dice: 0.8115 | dice_neg: 0.9401 | dice_pos: 0.6936\n",
      "\n",
      "Starting epoch: 103 | phase: train | ⏰: 11:51:57\n",
      "Loss: 0.0053 | IoU: 0.6579 | dice: 0.8603 | dice_neg: 0.9628 | dice_pos: 0.7737\n",
      "Starting epoch: 103 | phase: val | ⏰: 11:59:19\n",
      "Loss: 0.0102 | IoU: 0.5750 | dice: 0.8100 | dice_neg: 0.9321 | dice_pos: 0.6983\n",
      "\n",
      "Starting epoch: 104 | phase: train | ⏰: 12:00:38\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8591 | dice_neg: 0.9589 | dice_pos: 0.7728\n",
      "Starting epoch: 104 | phase: val | ⏰: 12:08:06\n",
      "Loss: 0.0102 | IoU: 0.5729 | dice: 0.8133 | dice_neg: 0.9478 | dice_pos: 0.6954\n",
      "\n",
      "Starting epoch: 105 | phase: train | ⏰: 12:09:24\n",
      "Loss: 0.0053 | IoU: 0.6587 | dice: 0.8586 | dice_neg: 0.9588 | dice_pos: 0.7744\n",
      "Starting epoch: 105 | phase: val | ⏰: 12:16:44\n",
      "Loss: 0.0104 | IoU: 0.5728 | dice: 0.8112 | dice_neg: 0.9425 | dice_pos: 0.6958\n",
      "\n",
      "Starting epoch: 106 | phase: train | ⏰: 12:18:01\n",
      "Loss: 0.0053 | IoU: 0.6585 | dice: 0.8590 | dice_neg: 0.9584 | dice_pos: 0.7746\n",
      "Starting epoch: 106 | phase: val | ⏰: 12:25:24\n",
      "Loss: 0.0101 | IoU: 0.5726 | dice: 0.8104 | dice_neg: 0.9397 | dice_pos: 0.6958\n",
      "\n",
      "Starting epoch: 107 | phase: train | ⏰: 12:26:42\n",
      "Loss: 0.0053 | IoU: 0.6586 | dice: 0.8588 | dice_neg: 0.9560 | dice_pos: 0.7748\n",
      "Starting epoch: 107 | phase: val | ⏰: 12:34:11\n",
      "Loss: 0.0102 | IoU: 0.5720 | dice: 0.8118 | dice_neg: 0.9436 | dice_pos: 0.6945\n",
      "\n",
      "Starting epoch: 108 | phase: train | ⏰: 12:35:36\n",
      "Loss: 0.0053 | IoU: 0.6577 | dice: 0.8600 | dice_neg: 0.9617 | dice_pos: 0.7737\n",
      "Starting epoch: 108 | phase: val | ⏰: 12:43:01\n",
      "Loss: 0.0102 | IoU: 0.5727 | dice: 0.8103 | dice_neg: 0.9369 | dice_pos: 0.6914\n",
      "\n",
      "Starting epoch: 109 | phase: train | ⏰: 12:44:18\n",
      "Loss: 0.0053 | IoU: 0.6569 | dice: 0.8590 | dice_neg: 0.9613 | dice_pos: 0.7731\n",
      "Starting epoch: 109 | phase: val | ⏰: 12:51:44\n",
      "Loss: 0.0101 | IoU: 0.5728 | dice: 0.8110 | dice_neg: 0.9330 | dice_pos: 0.6956\n",
      "\n",
      "Starting epoch: 110 | phase: train | ⏰: 12:53:04\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8595 | dice_neg: 0.9622 | dice_pos: 0.7730\n",
      "Starting epoch: 110 | phase: val | ⏰: 13:00:36\n",
      "Loss: 0.0103 | IoU: 0.5726 | dice: 0.8129 | dice_neg: 0.9420 | dice_pos: 0.6949\n",
      "\n",
      "Starting epoch: 111 | phase: train | ⏰: 13:01:56\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8593 | dice_neg: 0.9593 | dice_pos: 0.7741\n",
      "Starting epoch: 111 | phase: val | ⏰: 13:09:24\n",
      "Loss: 0.0104 | IoU: 0.5697 | dice: 0.8112 | dice_neg: 0.9359 | dice_pos: 0.6924\n",
      "\n",
      "Starting epoch: 112 | phase: train | ⏰: 13:10:44\n",
      "Loss: 0.0053 | IoU: 0.6575 | dice: 0.8613 | dice_neg: 0.9639 | dice_pos: 0.7733\n",
      "Starting epoch: 112 | phase: val | ⏰: 13:18:14\n",
      "Loss: 0.0102 | IoU: 0.5734 | dice: 0.8121 | dice_neg: 0.9441 | dice_pos: 0.6953\n",
      "\n",
      "Starting epoch: 113 | phase: train | ⏰: 13:19:32\n",
      "Loss: 0.0053 | IoU: 0.6560 | dice: 0.8565 | dice_neg: 0.9571 | dice_pos: 0.7719\n",
      "Starting epoch: 113 | phase: val | ⏰: 13:26:54\n",
      "Loss: 0.0103 | IoU: 0.5697 | dice: 0.8097 | dice_neg: 0.9421 | dice_pos: 0.6924\n",
      "\n",
      "Starting epoch: 114 | phase: train | ⏰: 13:28:11\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8601 | dice_neg: 0.9601 | dice_pos: 0.7745\n",
      "Starting epoch: 114 | phase: val | ⏰: 13:35:35\n",
      "Loss: 0.0102 | IoU: 0.5695 | dice: 0.8133 | dice_neg: 0.9491 | dice_pos: 0.6918\n",
      "\n",
      "Starting epoch: 115 | phase: train | ⏰: 13:36:52\n",
      "Loss: 0.0053 | IoU: 0.6577 | dice: 0.8582 | dice_neg: 0.9570 | dice_pos: 0.7738\n",
      "Starting epoch: 115 | phase: val | ⏰: 13:44:28\n",
      "Loss: 0.0104 | IoU: 0.5708 | dice: 0.8113 | dice_neg: 0.9339 | dice_pos: 0.6931\n",
      "\n",
      "Starting epoch: 116 | phase: train | ⏰: 13:45:45\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8593 | dice_neg: 0.9606 | dice_pos: 0.7743\n",
      "Starting epoch: 116 | phase: val | ⏰: 13:53:14\n",
      "Loss: 0.0104 | IoU: 0.5706 | dice: 0.8106 | dice_neg: 0.9416 | dice_pos: 0.6926\n",
      "\n",
      "Starting epoch: 117 | phase: train | ⏰: 13:54:34\n",
      "Loss: 0.0053 | IoU: 0.6578 | dice: 0.8606 | dice_neg: 0.9631 | dice_pos: 0.7737\n",
      "Starting epoch: 117 | phase: val | ⏰: 14:02:01\n",
      "Loss: 0.0105 | IoU: 0.5734 | dice: 0.8100 | dice_neg: 0.9384 | dice_pos: 0.6965\n",
      "\n",
      "Starting epoch: 118 | phase: train | ⏰: 14:03:17\n",
      "Loss: 0.0053 | IoU: 0.6577 | dice: 0.8577 | dice_neg: 0.9579 | dice_pos: 0.7738\n",
      "Starting epoch: 118 | phase: val | ⏰: 14:10:37\n",
      "Loss: 0.0103 | IoU: 0.5740 | dice: 0.8107 | dice_neg: 0.9454 | dice_pos: 0.6973\n",
      "\n",
      "Starting epoch: 119 | phase: train | ⏰: 14:11:54\n",
      "Loss: 0.0053 | IoU: 0.6564 | dice: 0.8602 | dice_neg: 0.9612 | dice_pos: 0.7728\n",
      "Starting epoch: 119 | phase: val | ⏰: 14:19:16\n",
      "Loss: 0.0103 | IoU: 0.5685 | dice: 0.8107 | dice_neg: 0.9360 | dice_pos: 0.6905\n",
      "\n",
      "Starting epoch: 120 | phase: train | ⏰: 14:20:32\n",
      "Loss: 0.0053 | IoU: 0.6579 | dice: 0.8605 | dice_neg: 0.9625 | dice_pos: 0.7738\n",
      "Starting epoch: 120 | phase: val | ⏰: 14:27:53\n",
      "Loss: 0.0107 | IoU: 0.5674 | dice: 0.8105 | dice_neg: 0.9394 | dice_pos: 0.6894\n",
      "\n",
      "Starting epoch: 121 | phase: train | ⏰: 14:29:11\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8601 | dice_neg: 0.9621 | dice_pos: 0.7746\n",
      "Starting epoch: 121 | phase: val | ⏰: 14:36:48\n",
      "Loss: 0.0103 | IoU: 0.5746 | dice: 0.8117 | dice_neg: 0.9383 | dice_pos: 0.6970\n",
      "\n",
      "Starting epoch: 122 | phase: train | ⏰: 14:38:10\n",
      "Loss: 0.0053 | IoU: 0.6590 | dice: 0.8608 | dice_neg: 0.9616 | dice_pos: 0.7752\n",
      "Starting epoch: 122 | phase: val | ⏰: 14:45:31\n",
      "Loss: 0.0102 | IoU: 0.5740 | dice: 0.8112 | dice_neg: 0.9430 | dice_pos: 0.6965\n",
      "\n",
      "Starting epoch: 123 | phase: train | ⏰: 14:46:50\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8602 | dice_neg: 0.9606 | dice_pos: 0.7747\n",
      "Starting epoch: 123 | phase: val | ⏰: 14:54:19\n",
      "Loss: 0.0103 | IoU: 0.5702 | dice: 0.8110 | dice_neg: 0.9458 | dice_pos: 0.6925\n",
      "\n",
      "Starting epoch: 124 | phase: train | ⏰: 14:55:36\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8601 | dice_neg: 0.9616 | dice_pos: 0.7729\n",
      "Starting epoch: 124 | phase: val | ⏰: 15:02:57\n",
      "Loss: 0.0103 | IoU: 0.5736 | dice: 0.8098 | dice_neg: 0.9391 | dice_pos: 0.6917\n",
      "\n",
      "Starting epoch: 125 | phase: train | ⏰: 15:04:13\n",
      "Loss: 0.0053 | IoU: 0.6560 | dice: 0.8596 | dice_neg: 0.9622 | dice_pos: 0.7723\n",
      "Starting epoch: 125 | phase: val | ⏰: 15:11:33\n",
      "Loss: 0.0102 | IoU: 0.5739 | dice: 0.8121 | dice_neg: 0.9441 | dice_pos: 0.6966\n",
      "\n",
      "Starting epoch: 126 | phase: train | ⏰: 15:12:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0053 | IoU: 0.6564 | dice: 0.8596 | dice_neg: 0.9619 | dice_pos: 0.7722\n",
      "Starting epoch: 126 | phase: val | ⏰: 15:20:12\n",
      "Loss: 0.0102 | IoU: 0.5683 | dice: 0.8110 | dice_neg: 0.9436 | dice_pos: 0.6915\n",
      "\n",
      "Starting epoch: 127 | phase: train | ⏰: 15:21:33\n",
      "Loss: 0.0053 | IoU: 0.6574 | dice: 0.8593 | dice_neg: 0.9605 | dice_pos: 0.7734\n",
      "Starting epoch: 127 | phase: val | ⏰: 15:29:08\n",
      "Loss: 0.0104 | IoU: 0.5671 | dice: 0.8111 | dice_neg: 0.9425 | dice_pos: 0.6894\n",
      "\n",
      "Starting epoch: 128 | phase: train | ⏰: 15:30:30\n",
      "Loss: 0.0053 | IoU: 0.6575 | dice: 0.8577 | dice_neg: 0.9567 | dice_pos: 0.7731\n",
      "Starting epoch: 128 | phase: val | ⏰: 15:38:05\n",
      "Loss: 0.0104 | IoU: 0.5672 | dice: 0.8092 | dice_neg: 0.9335 | dice_pos: 0.6900\n",
      "\n",
      "Starting epoch: 129 | phase: train | ⏰: 15:39:26\n",
      "Loss: 0.0053 | IoU: 0.6568 | dice: 0.8585 | dice_neg: 0.9600 | dice_pos: 0.7730\n",
      "Starting epoch: 129 | phase: val | ⏰: 15:47:05\n",
      "Loss: 0.0103 | IoU: 0.5725 | dice: 0.8136 | dice_neg: 0.9484 | dice_pos: 0.6950\n",
      "\n",
      "Starting epoch: 130 | phase: train | ⏰: 15:48:28\n",
      "Loss: 0.0054 | IoU: 0.6560 | dice: 0.8580 | dice_neg: 0.9573 | dice_pos: 0.7721\n",
      "Starting epoch: 130 | phase: val | ⏰: 15:55:57\n",
      "Loss: 0.0103 | IoU: 0.5713 | dice: 0.8131 | dice_neg: 0.9463 | dice_pos: 0.6894\n",
      "\n",
      "Starting epoch: 131 | phase: train | ⏰: 15:57:22\n",
      "Loss: 0.0053 | IoU: 0.6562 | dice: 0.8587 | dice_neg: 0.9592 | dice_pos: 0.7723\n",
      "Starting epoch: 131 | phase: val | ⏰: 16:04:45\n",
      "Loss: 0.0102 | IoU: 0.5703 | dice: 0.8076 | dice_neg: 0.9361 | dice_pos: 0.6934\n",
      "\n",
      "Starting epoch: 132 | phase: train | ⏰: 16:06:03\n",
      "Loss: 0.0053 | IoU: 0.6550 | dice: 0.8591 | dice_neg: 0.9614 | dice_pos: 0.7710\n",
      "Starting epoch: 132 | phase: val | ⏰: 16:13:27\n",
      "Loss: 0.0103 | IoU: 0.5763 | dice: 0.8086 | dice_neg: 0.9353 | dice_pos: 0.6996\n",
      "\n",
      "Starting epoch: 133 | phase: train | ⏰: 16:14:46\n",
      "Loss: 0.0053 | IoU: 0.6585 | dice: 0.8592 | dice_neg: 0.9608 | dice_pos: 0.7745\n",
      "Starting epoch: 133 | phase: val | ⏰: 16:22:10\n",
      "Loss: 0.0102 | IoU: 0.5761 | dice: 0.8120 | dice_neg: 0.9401 | dice_pos: 0.6987\n",
      "\n",
      "Starting epoch: 134 | phase: train | ⏰: 16:23:29\n",
      "Loss: 0.0054 | IoU: 0.6566 | dice: 0.8581 | dice_neg: 0.9593 | dice_pos: 0.7722\n",
      "Starting epoch: 134 | phase: val | ⏰: 16:30:58\n",
      "Loss: 0.0103 | IoU: 0.5705 | dice: 0.8092 | dice_neg: 0.9390 | dice_pos: 0.6927\n",
      "\n",
      "Starting epoch: 135 | phase: train | ⏰: 16:32:20\n",
      "Loss: 0.0053 | IoU: 0.6546 | dice: 0.8586 | dice_neg: 0.9602 | dice_pos: 0.7701\n",
      "Starting epoch: 135 | phase: val | ⏰: 16:39:58\n",
      "Loss: 0.0101 | IoU: 0.5707 | dice: 0.8105 | dice_neg: 0.9382 | dice_pos: 0.6897\n",
      "\n",
      "Starting epoch: 136 | phase: train | ⏰: 16:41:21\n",
      "Loss: 0.0053 | IoU: 0.6588 | dice: 0.8600 | dice_neg: 0.9602 | dice_pos: 0.7752\n",
      "Starting epoch: 136 | phase: val | ⏰: 16:49:00\n",
      "Loss: 0.0104 | IoU: 0.5681 | dice: 0.8071 | dice_neg: 0.9371 | dice_pos: 0.6904\n",
      "\n",
      "Starting epoch: 137 | phase: train | ⏰: 16:50:19\n",
      "Loss: 0.0053 | IoU: 0.6584 | dice: 0.8584 | dice_neg: 0.9575 | dice_pos: 0.7745\n",
      "Starting epoch: 137 | phase: val | ⏰: 16:57:46\n",
      "Loss: 0.0105 | IoU: 0.5685 | dice: 0.8097 | dice_neg: 0.9458 | dice_pos: 0.6905\n",
      "\n",
      "Starting epoch: 138 | phase: train | ⏰: 16:59:05\n",
      "Loss: 0.0054 | IoU: 0.6579 | dice: 0.8575 | dice_neg: 0.9569 | dice_pos: 0.7734\n",
      "Starting epoch: 138 | phase: val | ⏰: 17:06:37\n",
      "Loss: 0.0103 | IoU: 0.5686 | dice: 0.8101 | dice_neg: 0.9442 | dice_pos: 0.6909\n",
      "\n",
      "Starting epoch: 139 | phase: train | ⏰: 17:07:54\n",
      "Loss: 0.0053 | IoU: 0.6565 | dice: 0.8582 | dice_neg: 0.9591 | dice_pos: 0.7721\n",
      "Starting epoch: 139 | phase: val | ⏰: 17:15:23\n",
      "Loss: 0.0102 | IoU: 0.5728 | dice: 0.8107 | dice_neg: 0.9362 | dice_pos: 0.6918\n",
      "\n",
      "Starting epoch: 140 | phase: train | ⏰: 17:16:44\n",
      "Loss: 0.0053 | IoU: 0.6588 | dice: 0.8597 | dice_neg: 0.9599 | dice_pos: 0.7748\n",
      "Starting epoch: 140 | phase: val | ⏰: 17:24:18\n",
      "Loss: 0.0105 | IoU: 0.5702 | dice: 0.8097 | dice_neg: 0.9372 | dice_pos: 0.6930\n",
      "\n",
      "Starting epoch: 141 | phase: train | ⏰: 17:25:41\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8585 | dice_neg: 0.9575 | dice_pos: 0.7746\n",
      "Starting epoch: 141 | phase: val | ⏰: 17:33:21\n",
      "Loss: 0.0103 | IoU: 0.5705 | dice: 0.8112 | dice_neg: 0.9473 | dice_pos: 0.6929\n",
      "\n",
      "Starting epoch: 142 | phase: train | ⏰: 17:34:43\n",
      "Loss: 0.0053 | IoU: 0.6581 | dice: 0.8594 | dice_neg: 0.9602 | dice_pos: 0.7739\n",
      "Starting epoch: 142 | phase: val | ⏰: 17:42:18\n",
      "Loss: 0.0103 | IoU: 0.5684 | dice: 0.8111 | dice_neg: 0.9430 | dice_pos: 0.6907\n",
      "\n",
      "Starting epoch: 143 | phase: train | ⏰: 17:43:37\n",
      "Loss: 0.0054 | IoU: 0.6563 | dice: 0.8587 | dice_neg: 0.9587 | dice_pos: 0.7723\n",
      "Starting epoch: 143 | phase: val | ⏰: 17:51:07\n",
      "Loss: 0.0104 | IoU: 0.5709 | dice: 0.8123 | dice_neg: 0.9407 | dice_pos: 0.6932\n",
      "\n",
      "Starting epoch: 144 | phase: train | ⏰: 17:52:27\n",
      "Loss: 0.0053 | IoU: 0.6579 | dice: 0.8587 | dice_neg: 0.9595 | dice_pos: 0.7742\n",
      "Starting epoch: 144 | phase: val | ⏰: 17:59:58\n",
      "Loss: 0.0102 | IoU: 0.5682 | dice: 0.8133 | dice_neg: 0.9436 | dice_pos: 0.6910\n",
      "\n",
      "Starting epoch: 145 | phase: train | ⏰: 18:01:18\n",
      "Loss: 0.0053 | IoU: 0.6577 | dice: 0.8606 | dice_neg: 0.9622 | dice_pos: 0.7740\n",
      "Starting epoch: 145 | phase: val | ⏰: 18:08:52\n",
      "Loss: 0.0102 | IoU: 0.5719 | dice: 0.8090 | dice_neg: 0.9409 | dice_pos: 0.6946\n",
      "\n",
      "Starting epoch: 146 | phase: train | ⏰: 18:10:21\n",
      "Loss: 0.0053 | IoU: 0.6576 | dice: 0.8608 | dice_neg: 0.9624 | dice_pos: 0.7736\n",
      "Starting epoch: 146 | phase: val | ⏰: 18:17:52\n",
      "Loss: 0.0102 | IoU: 0.5771 | dice: 0.8117 | dice_neg: 0.9452 | dice_pos: 0.7001\n",
      "\n",
      "Starting epoch: 147 | phase: train | ⏰: 18:19:13\n",
      "Loss: 0.0053 | IoU: 0.6570 | dice: 0.8586 | dice_neg: 0.9581 | dice_pos: 0.7729\n",
      "Starting epoch: 147 | phase: val | ⏰: 18:26:39\n",
      "Loss: 0.0102 | IoU: 0.5728 | dice: 0.8105 | dice_neg: 0.9406 | dice_pos: 0.6952\n",
      "\n",
      "Starting epoch: 148 | phase: train | ⏰: 18:27:57\n",
      "Loss: 0.0053 | IoU: 0.6572 | dice: 0.8607 | dice_neg: 0.9650 | dice_pos: 0.7732\n",
      "Starting epoch: 148 | phase: val | ⏰: 18:35:26\n",
      "Loss: 0.0102 | IoU: 0.5752 | dice: 0.8076 | dice_neg: 0.9294 | dice_pos: 0.6979\n",
      "\n",
      "Starting epoch: 149 | phase: train | ⏰: 18:36:46\n",
      "Loss: 0.0053 | IoU: 0.6564 | dice: 0.8599 | dice_neg: 0.9623 | dice_pos: 0.7720\n",
      "Starting epoch: 149 | phase: val | ⏰: 18:44:22\n",
      "Loss: 0.0103 | IoU: 0.5720 | dice: 0.8130 | dice_neg: 0.9466 | dice_pos: 0.6906\n",
      "\n",
      "Starting epoch: 150 | phase: train | ⏰: 18:45:44\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8591 | dice_neg: 0.9575 | dice_pos: 0.7740\n",
      "Starting epoch: 150 | phase: val | ⏰: 18:53:22\n",
      "Loss: 0.0101 | IoU: 0.5801 | dice: 0.8115 | dice_neg: 0.9376 | dice_pos: 0.7033\n",
      "\n",
      "Starting epoch: 151 | phase: train | ⏰: 18:54:44\n",
      "Loss: 0.0053 | IoU: 0.6577 | dice: 0.8588 | dice_neg: 0.9585 | dice_pos: 0.7733\n",
      "Starting epoch: 151 | phase: val | ⏰: 19:02:21\n",
      "Loss: 0.0101 | IoU: 0.5740 | dice: 0.8105 | dice_neg: 0.9343 | dice_pos: 0.6927\n",
      "\n",
      "Starting epoch: 152 | phase: train | ⏰: 19:03:41\n",
      "Loss: 0.0053 | IoU: 0.6549 | dice: 0.8568 | dice_neg: 0.9581 | dice_pos: 0.7710\n",
      "Starting epoch: 152 | phase: val | ⏰: 19:11:14\n",
      "Loss: 0.0103 | IoU: 0.5711 | dice: 0.8135 | dice_neg: 0.9455 | dice_pos: 0.6890\n",
      "\n",
      "Starting epoch: 153 | phase: train | ⏰: 19:12:37\n",
      "Loss: 0.0054 | IoU: 0.6571 | dice: 0.8595 | dice_neg: 0.9617 | dice_pos: 0.7727\n",
      "Starting epoch: 153 | phase: val | ⏰: 19:20:31\n",
      "Loss: 0.0101 | IoU: 0.5745 | dice: 0.8121 | dice_neg: 0.9437 | dice_pos: 0.6978\n",
      "\n",
      "Starting epoch: 154 | phase: train | ⏰: 19:21:53\n",
      "Loss: 0.0053 | IoU: 0.6589 | dice: 0.8606 | dice_neg: 0.9621 | dice_pos: 0.7747\n",
      "Starting epoch: 154 | phase: val | ⏰: 19:29:25\n",
      "Loss: 0.0102 | IoU: 0.5727 | dice: 0.8117 | dice_neg: 0.9435 | dice_pos: 0.6912\n",
      "\n",
      "Starting epoch: 155 | phase: train | ⏰: 19:30:43\n",
      "Loss: 0.0053 | IoU: 0.6591 | dice: 0.8594 | dice_neg: 0.9591 | dice_pos: 0.7752\n",
      "Starting epoch: 155 | phase: val | ⏰: 19:38:09\n",
      "Loss: 0.0103 | IoU: 0.5692 | dice: 0.8112 | dice_neg: 0.9465 | dice_pos: 0.6920\n",
      "\n",
      "Starting epoch: 156 | phase: train | ⏰: 19:39:29\n",
      "Loss: 0.0053 | IoU: 0.6556 | dice: 0.8598 | dice_neg: 0.9614 | dice_pos: 0.7714\n",
      "Starting epoch: 156 | phase: val | ⏰: 19:46:54\n",
      "Loss: 0.0103 | IoU: 0.5735 | dice: 0.8120 | dice_neg: 0.9409 | dice_pos: 0.6960\n",
      "\n",
      "Starting epoch: 157 | phase: train | ⏰: 19:48:12\n",
      "Loss: 0.0053 | IoU: 0.6582 | dice: 0.8584 | dice_neg: 0.9581 | dice_pos: 0.7740\n",
      "Starting epoch: 157 | phase: val | ⏰: 19:55:37\n",
      "Loss: 0.0103 | IoU: 0.5704 | dice: 0.8130 | dice_neg: 0.9479 | dice_pos: 0.6928\n",
      "\n",
      "Starting epoch: 158 | phase: train | ⏰: 19:56:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0053 | IoU: 0.6562 | dice: 0.8596 | dice_neg: 0.9611 | dice_pos: 0.7723\n",
      "Starting epoch: 158 | phase: val | ⏰: 20:04:22\n",
      "Loss: 0.0102 | IoU: 0.5743 | dice: 0.8137 | dice_neg: 0.9463 | dice_pos: 0.6966\n",
      "\n",
      "Starting epoch: 159 | phase: train | ⏰: 20:05:40\n",
      "Loss: 0.0053 | IoU: 0.6563 | dice: 0.8591 | dice_neg: 0.9611 | dice_pos: 0.7721\n",
      "Starting epoch: 159 | phase: val | ⏰: 20:13:05\n",
      "Loss: 0.0103 | IoU: 0.5712 | dice: 0.8141 | dice_neg: 0.9471 | dice_pos: 0.6887\n",
      "\n",
      "Starting epoch: 160 | phase: train | ⏰: 20:14:26\n",
      "Loss: 0.0054 | IoU: 0.6558 | dice: 0.8585 | dice_neg: 0.9572 | dice_pos: 0.7715\n",
      "Starting epoch: 160 | phase: val | ⏰: 20:22:04\n",
      "Loss: 0.0102 | IoU: 0.5747 | dice: 0.8115 | dice_neg: 0.9451 | dice_pos: 0.6928\n",
      "\n",
      "Starting epoch: 161 | phase: train | ⏰: 20:23:35\n",
      "Loss: 0.0054 | IoU: 0.6564 | dice: 0.8571 | dice_neg: 0.9553 | dice_pos: 0.7730\n",
      "Starting epoch: 161 | phase: val | ⏰: 20:31:03\n",
      "Loss: 0.0104 | IoU: 0.5700 | dice: 0.8102 | dice_neg: 0.9403 | dice_pos: 0.6929\n",
      "\n",
      "Starting epoch: 162 | phase: train | ⏰: 20:32:21\n",
      "Loss: 0.0053 | IoU: 0.6560 | dice: 0.8595 | dice_neg: 0.9587 | dice_pos: 0.7722\n",
      "Starting epoch: 162 | phase: val | ⏰: 20:39:55\n",
      "Loss: 0.0102 | IoU: 0.5721 | dice: 0.8110 | dice_neg: 0.9404 | dice_pos: 0.6909\n",
      "\n",
      "Starting epoch: 163 | phase: train | ⏰: 20:41:17\n",
      "Loss: 0.0054 | IoU: 0.6565 | dice: 0.8576 | dice_neg: 0.9586 | dice_pos: 0.7722\n",
      "Starting epoch: 163 | phase: val | ⏰: 20:48:46\n",
      "Loss: 0.0103 | IoU: 0.5781 | dice: 0.8097 | dice_neg: 0.9272 | dice_pos: 0.7010\n",
      "\n",
      "Starting epoch: 164 | phase: train | ⏰: 20:50:04\n",
      "Loss: 0.0053 | IoU: 0.6571 | dice: 0.8597 | dice_neg: 0.9605 | dice_pos: 0.7735\n",
      "Starting epoch: 164 | phase: val | ⏰: 20:57:32\n",
      "Loss: 0.0105 | IoU: 0.5714 | dice: 0.8095 | dice_neg: 0.9350 | dice_pos: 0.6939\n",
      "\n",
      "Starting epoch: 165 | phase: train | ⏰: 20:58:51\n",
      "Loss: 0.0054 | IoU: 0.6561 | dice: 0.8598 | dice_neg: 0.9623 | dice_pos: 0.7716\n",
      "Starting epoch: 165 | phase: val | ⏰: 21:06:20\n",
      "Loss: 0.0104 | IoU: 0.5674 | dice: 0.8117 | dice_neg: 0.9486 | dice_pos: 0.6895\n",
      "\n",
      "Starting epoch: 166 | phase: train | ⏰: 21:07:40\n",
      "Loss: 0.0053 | IoU: 0.6565 | dice: 0.8590 | dice_neg: 0.9609 | dice_pos: 0.7722\n",
      "Starting epoch: 166 | phase: val | ⏰: 21:15:07\n",
      "Loss: 0.0102 | IoU: 0.5710 | dice: 0.8123 | dice_neg: 0.9435 | dice_pos: 0.6935\n",
      "\n",
      "Starting epoch: 167 | phase: train | ⏰: 21:16:26\n",
      "Loss: 0.0053 | IoU: 0.6568 | dice: 0.8582 | dice_neg: 0.9589 | dice_pos: 0.7730\n",
      "Starting epoch: 167 | phase: val | ⏰: 21:23:52\n",
      "Loss: 0.0102 | IoU: 0.5761 | dice: 0.8123 | dice_neg: 0.9425 | dice_pos: 0.6997\n",
      "\n",
      "Starting epoch: 168 | phase: train | ⏰: 21:25:14\n",
      "Loss: 0.0053 | IoU: 0.6564 | dice: 0.8580 | dice_neg: 0.9586 | dice_pos: 0.7721\n",
      "Starting epoch: 168 | phase: val | ⏰: 21:33:04\n",
      "Loss: 0.0103 | IoU: 0.5740 | dice: 0.8102 | dice_neg: 0.9405 | dice_pos: 0.6966\n",
      "\n",
      "Starting epoch: 169 | phase: train | ⏰: 21:34:23\n",
      "Loss: 0.0053 | IoU: 0.6574 | dice: 0.8602 | dice_neg: 0.9622 | dice_pos: 0.7732\n",
      "Starting epoch: 169 | phase: val | ⏰: 21:41:48\n",
      "Loss: 0.0103 | IoU: 0.5671 | dice: 0.8107 | dice_neg: 0.9439 | dice_pos: 0.6900\n",
      "\n",
      "Starting epoch: 170 | phase: train | ⏰: 21:43:07\n",
      "Loss: 0.0053 | IoU: 0.6580 | dice: 0.8609 | dice_neg: 0.9629 | dice_pos: 0.7736\n",
      "Starting epoch: 170 | phase: val | ⏰: 21:50:32\n",
      "Loss: 0.0104 | IoU: 0.5675 | dice: 0.8123 | dice_neg: 0.9529 | dice_pos: 0.6895\n",
      "\n",
      "Starting epoch: 171 | phase: train | ⏰: 21:51:50\n",
      "Loss: 0.0053 | IoU: 0.6556 | dice: 0.8590 | dice_neg: 0.9614 | dice_pos: 0.7713\n",
      "Starting epoch: 171 | phase: val | ⏰: 21:59:17\n",
      "Loss: 0.0102 | IoU: 0.5747 | dice: 0.8104 | dice_neg: 0.9393 | dice_pos: 0.6975\n",
      "\n",
      "Starting epoch: 172 | phase: train | ⏰: 22:00:34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05f46443fc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-aef570d2ca11>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             state = {\n\u001b[1;32m     81\u001b[0m                 \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-aef570d2ca11>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, epoch, phase)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mmeter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING\n",
    "losses = model_trainer.losses\n",
    "dice_scores = model_trainer.dice_scores # overall dice\n",
    "iou_scores = model_trainer.iou_scores\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
    "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
    "    plt.legend(); \n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"BCE loss\")\n",
    "plot(dice_scores, \"Dice score\")\n",
    "plot(iou_scores, \"IoU score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction and submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training and validation takes about ~400 minutes which exceeds Kaggle's GPU usage limit of 60 minutes, we won't be able to submit the `submission.csv` file generated from this kernel. So, for test prediction and submission I've written a separate [UNet inference kernel](https://www.kaggle.com/rishabhiitbhu/unet-pytorch-inference-kernel), make sure you add the `model.pth` file generated from this kernel as dataset to test inference kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used resnet-18 architecture in this kernel. It scores ~0.89 on LB. Try to play around with other architectures of `segmenation_models.pytorch` and see what works best for you, let me know in the comments :) and do upvote if you liked this kernel, I need some medals too. 😬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "\n",
    "Few kernels from which I've borrowed some cod[](http://)e:\n",
    "\n",
    "* https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "* https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n",
    "\n",
    "A big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https://www.kaggle.com/abhishek), [@Yury](https://www.kaggle.com/deyury), [@Heng](https://www.kaggle.com/hengck23), [@Ekhtiar](https://www.kaggle.com/ekhtiar), [@lafoss](https://www.kaggle.com/iafoss), [@Siddhartha](https://www.kaggle.com/meaninglesslives), [@xhulu](https://www.kaggle.com/xhlulu), and the list goes on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1171px",
    "right": "20px",
    "top": "84px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
