{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet starter for Steel defect detection challenge\n",
    "\n",
    "\n",
    "This kernel uses a UNet model with pretrained resnet18 encoder for this challenge, with simple augmentations using albumentations library, uses BCE loss, metrics like Dice and IoU. I've used [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) which comes with a lot pre-implemented segmentation architectures. This is a modified version of my previous [kernel](https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch) for [siim-acr-pneumothorax-segmentation](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/) competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As internet is not allowed for this competition, I tried installing `segmentation_models.pytorch` by source using pip but due to some reasons it didn't work. So, as a [Jugaad](https://en.wikipedia.org/wiki/Jugaad) I took all of `segmentation_models.pytorch`'s UNet code and wrote it in a single file and added it as a dataset so as to use it for this kernel, its dependency [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch) is also added as a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/qubvel/segmentation_models.pytorch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'deepnetv3'\n",
    "mask_size = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# !pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\n",
    "# package_path = './unetmodelscript/' # add unet script dataset\n",
    "# import sys\n",
    "# sys.path.append(package_path)\n",
    "# from model import Unet # import Unet model from the script\n",
    "import segmentation_models_pytorch as smp #import Unet, FPN, PSPNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.torch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from radam import RAdam\n",
    "\n",
    "from torchsample.callbacks import EarlyStopping\n",
    "from lovasz_loss import LovaszSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, mask_size, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * mask_size, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, mask_size, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.5), # only horizontal flip as of now\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Resize(256, mask_size),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more utility functions\n",
    "\n",
    "Dice and IoU metric implementations, metric logger for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.dice_pos_scores.append(dice_pos)\n",
    "        self.dice_neg_scores.append(dice_neg)\n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        dice_neg = np.mean(self.dice_neg_scores)\n",
    "        dice_pos = np.mean(self.dice_pos_scores)\n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        return dices, iou\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
    "    return dice, iou\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "    return ious if ious else [1]\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCESoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, w1=1, w2=1):\n",
    "        super(BCESoftDiceLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # BCELoss2d\n",
    "        probs        = torch.sigmoid(logits)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        bce_loss = self.bce_loss(probs_flat, targets_flat)\n",
    "        \n",
    "        # SoftDiceLoss\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1  = probs.view(num,-1)\n",
    "        m2  = targets.view(num,-1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "        soft_dice_loss = 1- score.sum()/num\n",
    "        \n",
    "        return self.w1 * bce_loss + self.w2 * soft_dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /tmp/.cache/torch/checkpoints/\n",
    "# !cp ../input/resnet18/resnet18.pth /tmp/.cache/torch/checkpoints/resnet18-5c106cde.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/frank/.cache/torch/hub/pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "# model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "# model = smp.FPN(encoder_name, encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "model = torch.hub.load('pytorch/vision', \n",
    "                       'deeplabv3_resnet101', \n",
    "                       pretrained=False,\n",
    "                       num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "# model.set_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # a *deeper* look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 3\n",
    "        self.batch_size = {\"train\": 2, \"val\": 2}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.lr = 5e-4\n",
    "        self.num_epochs = 1000\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        # self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        # self.criterion = LovaszSoftmax()\n",
    "        # self.criterion = BCESoftDiceLoss(w1=1, w2=1)\n",
    "        # self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.optimizer = RAdam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        outputs = self.net(images)['out']\n",
    "        # print(outputs)\n",
    "        # print(outputs.shape)\n",
    "        # print(masks.shape)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"./\"+encoder_name+\"_model.pth\")\n",
    "#             if epoch % 10 == 0:\n",
    "            torch.save(state, \"./\"+encoder_name+\"_model_epoch_\"+str(epoch)+\".pth\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/sample_submission.csv'\n",
    "train_df_path = '../input/train.csv'\n",
    "data_folder = \"../input/\"\n",
    "test_data_folder = \"../input/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | ⏰: 01:27:38\n",
      "Loss: 0.2703 | IoU: 0.0576 | dice: 0.2326 | dice_neg: 0.2998 | dice_pos: 0.0653\n",
      "Starting epoch: 0 | phase: val | ⏰: 02:30:25\n",
      "Loss: 0.0918 | IoU: 0.1470 | dice: 0.4177 | dice_neg: 0.4865 | dice_pos: 0.1556\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 1 | phase: train | ⏰: 02:34:39\n",
      "Loss: 0.0513 | IoU: 0.2188 | dice: 0.4698 | dice_neg: 0.4929 | dice_pos: 0.2270\n",
      "Starting epoch: 1 | phase: val | ⏰: 03:37:20\n",
      "Loss: 0.0386 | IoU: 0.2111 | dice: 0.3861 | dice_neg: 0.3512 | dice_pos: 0.2219\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 2 | phase: train | ⏰: 03:41:36\n",
      "Loss: 0.0251 | IoU: 0.3284 | dice: 0.5786 | dice_neg: 0.5457 | dice_pos: 0.3328\n",
      "Starting epoch: 2 | phase: val | ⏰: 04:44:16\n",
      "Loss: 0.0238 | IoU: 0.2479 | dice: 0.4944 | dice_neg: 0.4714 | dice_pos: 0.2562\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 3 | phase: train | ⏰: 04:48:29\n",
      "Loss: 0.0185 | IoU: 0.3653 | dice: 0.6232 | dice_neg: 0.5762 | dice_pos: 0.3645\n",
      "Starting epoch: 3 | phase: val | ⏰: 05:51:08\n",
      "Loss: 0.0199 | IoU: 0.2968 | dice: 0.4715 | dice_neg: 0.4117 | dice_pos: 0.3113\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 4 | phase: train | ⏰: 05:55:22\n",
      "Loss: 0.0157 | IoU: 0.3846 | dice: 0.6448 | dice_neg: 0.5934 | dice_pos: 0.3799\n",
      "Starting epoch: 4 | phase: val | ⏰: 06:58:07\n",
      "Loss: 0.0193 | IoU: 0.3726 | dice: 0.5403 | dice_neg: 0.4356 | dice_pos: 0.3642\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 5 | phase: train | ⏰: 07:02:22\n",
      "Loss: 0.0142 | IoU: 0.4000 | dice: 0.6602 | dice_neg: 0.6069 | dice_pos: 0.3955\n",
      "Starting epoch: 5 | phase: val | ⏰: 08:04:57\n",
      "Loss: 0.0200 | IoU: 0.1722 | dice: 0.5279 | dice_neg: 0.6058 | dice_pos: 0.1891\n",
      "\n",
      "Starting epoch: 6 | phase: train | ⏰: 08:09:08\n",
      "Loss: 0.0135 | IoU: 0.4064 | dice: 0.6726 | dice_neg: 0.6089 | dice_pos: 0.3956\n",
      "Starting epoch: 6 | phase: val | ⏰: 09:11:47\n",
      "Loss: 0.0195 | IoU: 0.2885 | dice: 0.6347 | dice_neg: 0.6774 | dice_pos: 0.2910\n",
      "\n",
      "Starting epoch: 7 | phase: train | ⏰: 09:16:04\n",
      "Loss: 0.0122 | IoU: 0.4391 | dice: 0.6973 | dice_neg: 0.6218 | dice_pos: 0.4284\n",
      "Starting epoch: 7 | phase: val | ⏰: 10:18:48\n",
      "Loss: 0.0199 | IoU: 0.3130 | dice: 0.6165 | dice_neg: 0.6022 | dice_pos: 0.3185\n",
      "\n",
      "Starting epoch: 8 | phase: train | ⏰: 10:23:01\n",
      "Loss: 0.0138 | IoU: 0.4129 | dice: 0.6695 | dice_neg: 0.6028 | dice_pos: 0.4057\n",
      "Starting epoch: 8 | phase: val | ⏰: 11:25:39\n",
      "Loss: 0.3563 | IoU: 0.1807 | dice: 0.5731 | dice_neg: 0.6893 | dice_pos: 0.1763\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-05.\n",
      "\n",
      "Starting epoch: 9 | phase: train | ⏰: 11:29:52\n",
      "Loss: 0.0112 | IoU: 0.4656 | dice: 0.7291 | dice_neg: 0.6461 | dice_pos: 0.4538\n",
      "Starting epoch: 9 | phase: val | ⏰: 12:32:30\n",
      "Loss: 0.0961 | IoU: 0.2267 | dice: 0.6029 | dice_neg: 0.6854 | dice_pos: 0.2249\n",
      "\n",
      "Starting epoch: 10 | phase: train | ⏰: 12:36:46\n",
      "Loss: 0.0102 | IoU: 0.4999 | dice: 0.7483 | dice_neg: 0.6481 | dice_pos: 0.4833\n",
      "Starting epoch: 10 | phase: val | ⏰: 13:39:27\n",
      "Loss: 0.0648 | IoU: 0.2582 | dice: 0.5591 | dice_neg: 0.5927 | dice_pos: 0.2545\n",
      "\n",
      "Starting epoch: 11 | phase: train | ⏰: 13:43:39\n",
      "Loss: 0.0098 | IoU: 0.5116 | dice: 0.7510 | dice_neg: 0.6344 | dice_pos: 0.4858\n",
      "Starting epoch: 11 | phase: val | ⏰: 14:46:20\n",
      "Loss: 0.0163 | IoU: 0.4187 | dice: 0.7092 | dice_neg: 0.6516 | dice_pos: 0.4072\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 12 | phase: train | ⏰: 14:50:33\n",
      "Loss: 0.0094 | IoU: 0.5182 | dice: 0.7590 | dice_neg: 0.6457 | dice_pos: 0.4963\n",
      "Starting epoch: 12 | phase: val | ⏰: 15:53:15\n",
      "Loss: 0.0148 | IoU: 0.3744 | dice: 0.6882 | dice_neg: 0.6675 | dice_pos: 0.3707\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 13 | phase: train | ⏰: 15:57:30\n",
      "Loss: 0.0091 | IoU: 0.5286 | dice: 0.7654 | dice_neg: 0.6501 | dice_pos: 0.5043\n",
      "Starting epoch: 13 | phase: val | ⏰: 17:00:09\n",
      "Loss: 0.0204 | IoU: 0.3304 | dice: 0.6699 | dice_neg: 0.6762 | dice_pos: 0.3311\n",
      "\n",
      "Starting epoch: 14 | phase: train | ⏰: 17:04:20\n",
      "Loss: 0.0088 | IoU: 0.5338 | dice: 0.7753 | dice_neg: 0.6551 | dice_pos: 0.5046\n",
      "Starting epoch: 14 | phase: val | ⏰: 18:07:03\n",
      "Loss: 0.0342 | IoU: 0.2505 | dice: 0.5464 | dice_neg: 0.5736 | dice_pos: 0.2446\n",
      "\n",
      "Starting epoch: 15 | phase: train | ⏰: 18:11:17\n",
      "Loss: 0.0086 | IoU: 0.5398 | dice: 0.7764 | dice_neg: 0.6551 | dice_pos: 0.5125\n",
      "Starting epoch: 15 | phase: val | ⏰: 19:13:59\n",
      "Loss: 0.0492 | IoU: 0.2739 | dice: 0.6366 | dice_neg: 0.6798 | dice_pos: 0.2671\n",
      "\n",
      "Starting epoch: 16 | phase: train | ⏰: 19:18:13\n",
      "Loss: 0.0085 | IoU: 0.5460 | dice: 0.7801 | dice_neg: 0.6533 | dice_pos: 0.5161\n",
      "Starting epoch: 16 | phase: val | ⏰: 20:20:49\n",
      "Loss: 0.1927 | IoU: 0.2188 | dice: 0.5592 | dice_neg: 0.6289 | dice_pos: 0.2177\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-06.\n",
      "\n",
      "Starting epoch: 17 | phase: train | ⏰: 20:25:05\n",
      "Loss: 0.0078 | IoU: 0.5622 | dice: 0.7923 | dice_neg: 0.6591 | dice_pos: 0.5265\n",
      "Starting epoch: 17 | phase: val | ⏰: 21:27:44\n",
      "Loss: 0.0754 | IoU: 0.2673 | dice: 0.6333 | dice_neg: 0.6905 | dice_pos: 0.2603\n",
      "\n",
      "Starting epoch: 18 | phase: train | ⏰: 21:31:58\n",
      "Loss: 0.0077 | IoU: 0.5650 | dice: 0.7961 | dice_neg: 0.6703 | dice_pos: 0.5351\n",
      "Starting epoch: 18 | phase: val | ⏰: 22:34:23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05f46443fc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-15818a5cb7a6>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m             }\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-15818a5cb7a6>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, epoch, phase)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mmeter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (19,) and (18,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-096d5117c17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BCE loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dice score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IoU score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-096d5117c17e>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scores, name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'train {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'val {name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} plot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (19,) and (18,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT TRAINING\n",
    "losses = model_trainer.losses\n",
    "dice_scores = model_trainer.dice_scores # overall dice\n",
    "iou_scores = model_trainer.iou_scores\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
    "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
    "    plt.legend(); \n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"BCE loss\")\n",
    "plot(dice_scores, \"Dice score\")\n",
    "plot(iou_scores, \"IoU score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction and submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training and validation takes about ~400 minutes which exceeds Kaggle's GPU usage limit of 60 minutes, we won't be able to submit the `submission.csv` file generated from this kernel. So, for test prediction and submission I've written a separate [UNet inference kernel](https://www.kaggle.com/rishabhiitbhu/unet-pytorch-inference-kernel), make sure you add the `model.pth` file generated from this kernel as dataset to test inference kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used resnet-18 architecture in this kernel. It scores ~0.89 on LB. Try to play around with other architectures of `segmenation_models.pytorch` and see what works best for you, let me know in the comments :) and do upvote if you liked this kernel, I need some medals too. 😬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "\n",
    "Few kernels from which I've borrowed some cod[](http://)e:\n",
    "\n",
    "* https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "* https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n",
    "\n",
    "A big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https://www.kaggle.com/abhishek), [@Yury](https://www.kaggle.com/deyury), [@Heng](https://www.kaggle.com/hengck23), [@Ekhtiar](https://www.kaggle.com/ekhtiar), [@lafoss](https://www.kaggle.com/iafoss), [@Siddhartha](https://www.kaggle.com/meaninglesslives), [@xhulu](https://www.kaggle.com/xhlulu), and the list goes on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1266px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
